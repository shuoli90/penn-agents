---
type: lecture
date: 2025-02-06T15:30:00+1:00
title: LLM Agents: Why, What, How
tldr: "We discuss why LLM agents are designed, what their key components are, and how to design LLM agents for specific domains."
thumbnail: /static_files/presentations/agent_2.png
hide_from_announcments: false
links: 
    - url: https://drive.google.com/file/d/1a_nxTyBSPQg5quj66ecN0lKWoFz4KlCe/view?usp=drive_link
      name: In-context example
    - url: https://drive.google.com/file/d/1ygIrQTaAdPmI38GavuSyfFwtABOQXXcd/view?usp=drive_link
      name: Basics
---
**Suggested Readings:**
- [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300)
- [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via  Reinforcement Learning](https://arxiv.org/abs/2501.12948)
- [Scaling LLM Test-Time Compute Optimally Can be More Effective than Scaling Model Parameters](https://arxiv.org/abs/2408.03314)
- [Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement](https://arxiv.org/abs/2406.11176)
- [AgentTuning: Enabling Generalized Agent Abilities for LLMs](https://arxiv.org/abs/2310.12823)
- [Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents](https://arxiv.org/abs/2403.02502)
- [7B Model and 8K Examples: Emerging Reasoning with Reinforcement Learning is Both Effective and Efficient.](https://hkust-nlp.notion.site/simplerl-reason)
